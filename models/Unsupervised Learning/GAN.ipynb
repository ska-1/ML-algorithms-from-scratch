{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **GAN (Generative Adversarial Network)** is a type of machine learning framework used for generating new data that resembles a given dataset. It consists of two neural networks, a **Generator** and a **Discriminator**, which are trained together in an adversarial process.\n",
    "\n",
    "1. **Generator**:\n",
    "   - The Generator creates synthetic data (e.g., images, text, etc.) from random noise.\n",
    "   - Its goal is to produce data that is indistinguishable from real data.\n",
    "   - Example:\n",
    "     - Input: A vector of random numbers (noise).\n",
    "     - Output: A generated image resembling real images from the dataset.\n",
    "\n",
    "2. **Discriminator**:\n",
    "   - The Discriminator is a classifier that distinguishes between real data (from the dataset) and fake data (generated by the Generator).\n",
    "   - Its goal is to correctly identify whether the input is real or fake.\n",
    "\n",
    "### How GANs Work\n",
    "The Generator and Discriminator are trained simultaneously but with opposing goals:\n",
    "- The **Generator** tries to \"fool\" the Discriminator into believing that its outputs are real.\n",
    "- The **Discriminator** tries to correctly identify real versus fake inputs.\n",
    "\n",
    "### The Training Process\n",
    "1. **Train the Discriminator**:\n",
    "   - Use real data labeled as \"real\" and fake data (from the Generator) labeled as \"fake.\"\n",
    "   - The Discriminator minimizes its classification error.\n",
    "2. **Train the Generator**: \n",
    "   - Generate fake data and pass it to the Discriminator.\n",
    "   - The Generator's goal is to maximize the Discriminator's error (make the fake data look real).\n",
    "\n",
    "Over time, the Generator improves in creating realistic data, and the Discriminator improves in distinguishing real from fake. This adversarial training continues until the Generator produces data that is highly realistic.\n",
    "\n",
    "### Applications of GANs\n",
    "1. **Image Generation**:  Generating realistic images (e.g., faces, landscapes, objects).\n",
    "2. **Data Augmentation**: Creating synthetic data for training models in low-data scenarios.\n",
    "3. **Style Transfer**: Applying artistic styles to images (e.g., turning a photo into a painting style).\n",
    "4. **Super-Resolution**: Enhancing the resolution of images.\n",
    "5. **Text-to-Image Generation**: Generating images based on textual descriptions.\n",
    "6. **Video Generation**: Creating realistic videos or animations.\n",
    "\n",
    "### Example\n",
    "For a GAN trained on the **MNIST dataset** (handwritten digits):\n",
    "- **Input to Generator**: Random noise vector (e.g., 100 dimensions).\n",
    "- **Output from Generator**: An image resembling a handwritten digit.\n",
    "- **Input to Discriminator**: Either a real image (from the MNIST dataset) or a fake image (from the Generator).\n",
    "- **Output from Discriminator**: A probability of the input being real or fake.\n",
    "\n",
    "GANs are widely used in generative tasks and have revolutionized areas like computer vision and creative AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import nbimporter\n",
    "from optimizers import Adam\n",
    "from loss_functions import CrossEntropy\n",
    "from layers import Dense, Dropout, Flatten, Activation, Reshape, BatchNormalization\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "\n",
    "class GAN():\n",
    "    \"\"\"A Generative Adversarial Network with deep fully-connected neural nets as\n",
    "    Generator and Discriminator.\n",
    "\n",
    "    Training Data: MNIST Handwritten Digits (28x28 images)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28 \n",
    "        self.img_cols = 28\n",
    "        self.img_dim = self.img_rows * self.img_cols\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(learning_rate=0.0002, b1=0.5)\n",
    "        loss_function = CrossEntropy\n",
    "\n",
    "        # Build the discriminator\n",
    "        self.discriminator = self.build_discriminator(optimizer, loss_function)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator(optimizer, loss_function)\n",
    "\n",
    "        # Build the combined model\n",
    "        self.combined = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "        self.combined.layers.extend(self.generator.layers)\n",
    "        self.combined.layers.extend(self.discriminator.layers)\n",
    "\n",
    "        print ()\n",
    "        self.generator.summary(name=\"Generator\")\n",
    "        self.discriminator.summary(name=\"Discriminator\")\n",
    "\n",
    "    def build_generator(self, optimizer, loss_function):\n",
    "        \n",
    "        model = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "        model.add(Dense(256, input_shape=(self.latent_dim,)))\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(self.img_dim))\n",
    "        model.add(Activation('tanh'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self, optimizer, loss_function):\n",
    "        \n",
    "        model = NeuralNetwork(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "        model.add(Dense(512, input_shape=(self.img_dim,)))\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256))\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(2))\n",
    "        model.add(Activation('softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, n_epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "        X = mnist.data\n",
    "        y = mnist.target\n",
    "\n",
    "        # Rescale [-1, 1]\n",
    "        X = (X.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            self.discriminator.set_trainable(True)\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X.shape[0], half_batch)\n",
    "            imgs = X[idx]\n",
    "\n",
    "            # Sample noise to use as generator input\n",
    "            noise = np.random.normal(0, 1, (half_batch, self.latent_dim))\n",
    "\n",
    "            # Generate a half batch of images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Valid = [1, 0], Fake = [0, 1]\n",
    "            valid = np.concatenate((np.ones((half_batch, 1)), np.zeros((half_batch, 1))), axis=1)\n",
    "            fake = np.concatenate((np.zeros((half_batch, 1)), np.ones((half_batch, 1))), axis=1)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real, d_acc_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake, d_acc_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "            d_acc = 0.5 * (d_acc_real + d_acc_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # We only want to train the generator for the combined model\n",
    "            self.discriminator.set_trainable(False)\n",
    "\n",
    "            # Sample noise and use as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples as valid\n",
    "            valid = np.concatenate((np.ones((batch_size, 1)), np.zeros((batch_size, 1))), axis=1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss, g_acc = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Display the progress\n",
    "            print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, acc: %.2f%%]\" % (epoch, d_loss, 100*d_acc, g_loss, 100*g_acc))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5 # Grid size\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        # Generate images and reshape to image shape\n",
    "        gen_imgs = self.generator.predict(noise).reshape((-1, self.img_rows, self.img_cols))\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        plt.suptitle(\"Generative Adversarial Network\")\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt,:,:], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(n_epochs=200000, batch_size=64, save_interval=400)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
